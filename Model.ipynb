{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3507,
     "status": "ok",
     "timestamp": 1757777181774,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "626b3e72",
    "outputId": "e6a41d4a-990e-46a4-ff6b-324e2b26eebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5200 files belonging to 2 classes.\n",
      "Found 1416 files belonging to 2 classes.\n",
      "Class names: ['Fraud', 'Non-Fraud']\n",
      "Number of training batches: 163\n",
      "Number of testing batches: 45\n",
      "Found 1416 files belonging to 2 classes.\n",
      "Class names: ['Fraud', 'Non-Fraud']\n",
      "Number of training batches: 163\n",
      "Number of testing batches: 45\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the image dimensions and batch size\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size = 32 # Increased batch size for potentially faster training\n",
    "\n",
    "# Define the directories for training and testing data\n",
    "train_dir = os.path.join(os.getcwd(), \"data\", \"train\")\n",
    "test_dir = os.path.join(os.getcwd(), \"data\", \"test\")\n",
    "\n",
    "# Load the training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=(img_height, img_width),\n",
    "    interpolation='nearest',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load the testing dataset\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=(img_height, img_width),\n",
    "    interpolation='nearest',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False # No need to shuffle test data\n",
    ")\n",
    "\n",
    "# Get the class names\n",
    "class_names = train_ds.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Display the number of batches in the datasets\n",
    "print(\"Number of training batches:\", tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(\"Number of testing batches:\", tf.data.experimental.cardinality(test_ds).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0088fcd"
   },
   "source": [
    "Next, we will analyze and address the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41005,
     "status": "ok",
     "timestamp": 1757777223201,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "865780bd",
    "outputId": "608b7fe5-70a9-4732-8d0f-2acbe5a0abbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 00:09:34.885048: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:18: Filling up shuffle buffer (this may take a while): 37 of 256\n",
      "2025-09-14 00:09:52.425029: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n",
      "2025-09-14 00:09:52.425029: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud samples in training data: 200\n",
      "Non-fraud samples in training data: 5000\n",
      "Total samples in training data: 5200\n",
      "Class weights: {0: 13.0, 1: 0.52}\n"
     ]
    }
   ],
   "source": [
    "# Analyze class distribution in the training data\n",
    "fraud_count = 0\n",
    "non_fraud_count = 0\n",
    "num_classes = 2  # Set explicitly since Colab sometimes inferred this from context\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    fraud_count += tf.reduce_sum(tf.cast(labels == 0, tf.int32)).numpy()\n",
    "    non_fraud_count += tf.reduce_sum(tf.cast(labels == 1, tf.int32)).numpy()\n",
    "\n",
    "total_samples = fraud_count + non_fraud_count\n",
    "\n",
    "print(f\"Fraud samples in training data: {fraud_count}\")\n",
    "print(f\"Non-fraud samples in training data: {non_fraud_count}\")\n",
    "print(f\"Total samples in training data: {total_samples}\")\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "# The 'fraud' class is 0 and 'non fraud' is 1 based on the directory loading order\n",
    "weight_for_0 = (total_samples / (num_classes * fraud_count)) if fraud_count > 0 else 1.0\n",
    "weight_for_1 = (total_samples / (num_classes * non_fraud_count)) if non_fraud_count > 0 else 1.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(\"Class weights:\", class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02b32c76"
   },
   "source": [
    "Now, we will set up the data augmentation layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1757777223645,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "369e4490"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Create a data augmentation sequence\n",
    "data_augmentation = Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "  layers.RandomZoom(0.2),\n",
    "  layers.RandomContrast(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c2c40a8"
   },
   "source": [
    "Now, we will build the first model using transfer learning with EfficientNetV2-B0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 3829,
     "status": "ok",
     "timestamp": 1757777244765,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "6eb33b62",
    "outputId": "090be101-0559-41a3-c70b-5c70274473e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_2 (Sequential)   (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Functio  (None, 8, 8, 1280)        5919312   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5920593 (22.59 MB)\n",
      "Trainable params: 1281 (5.00 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Create the base model from the pre-trained EfficientNetV2B0 model\n",
    "base_model_effnet = EfficientNetV2B0(input_shape=(img_height, img_width, 3),\n",
    "                                     include_top=False,\n",
    "                                     weights='imagenet')\n",
    "\n",
    "# Freeze the base model to prevent its weights from being updated during training\n",
    "base_model_effnet.trainable = False\n",
    "\n",
    "# Build the model on top of the base model\n",
    "model_effnet = Sequential([\n",
    "    data_augmentation,\n",
    "    base_model_effnet,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1, activation='sigmoid') # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_effnet.compile(optimizer='adam',\n",
    "                     loss='binary_crossentropy', # Using binary crossentropy for binary classification\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model_effnet.build((None, img_height, img_width, 3))\n",
    "model_effnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4738d55f"
   },
   "source": [
    "Now, we will train the EfficientNetV2-B0 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969540,
     "status": "ok",
     "timestamp": 1757778226293,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "4be67959",
    "outputId": "fb2330cf-5a30-4766-9ad2-076140e41112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163/163 [==============================] - 460s 3s/step - loss: 0.5650 - accuracy: 0.7137 - val_loss: 0.2833 - val_accuracy: 0.9322\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 96s 587ms/step - loss: 0.4791 - accuracy: 0.7913 - val_loss: 0.3024 - val_accuracy: 0.9138\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 93s 568ms/step - loss: 0.4266 - accuracy: 0.8179 - val_loss: 0.2230 - val_accuracy: 0.9350\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 91s 554ms/step - loss: 0.3921 - accuracy: 0.8362 - val_loss: 0.2088 - val_accuracy: 0.9371\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 91s 555ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.2509 - val_accuracy: 0.9230\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 95s 578ms/step - loss: 0.3848 - accuracy: 0.8390 - val_loss: 0.2441 - val_accuracy: 0.9251\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 92s 562ms/step - loss: 0.3851 - accuracy: 0.8390 - val_loss: 0.2709 - val_accuracy: 0.9153\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 92s 560ms/step - loss: 0.3703 - accuracy: 0.8381 - val_loss: 0.2673 - val_accuracy: 0.9124\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 91s 556ms/step - loss: 0.3556 - accuracy: 0.8512 - val_loss: 0.2872 - val_accuracy: 0.8990\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 92s 559ms/step - loss: 0.3563 - accuracy: 0.8483 - val_loss: 0.2338 - val_accuracy: 0.9280\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 # You can adjust the number of epochs\n",
    "history_effnet = model_effnet.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=test_ds # Use test_ds as validation data for monitoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c8b7895"
   },
   "source": [
    "Now, we will build the second model using transfer learning with ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "executionInfo": {
     "elapsed": 5782,
     "status": "ok",
     "timestamp": 1757778250648,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "649a665d",
    "outputId": "294e859d-077d-4c6e-b3f4-a8b9d53ccbbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_2 (Sequential)   (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_8  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23589761 (89.99 MB)\n",
      "Trainable params: 2049 (8.00 KB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Create the base model from the pre-trained ResNet50 model\n",
    "base_model_resnet = ResNet50(input_shape=(img_height, img_width, 3),\n",
    "                             include_top=False,\n",
    "                             weights='imagenet')\n",
    "\n",
    "# Freeze the base model\n",
    "base_model_resnet.trainable = False\n",
    "\n",
    "# Build the model on top of the base model\n",
    "model_resnet = Sequential([\n",
    "    data_augmentation,\n",
    "    base_model_resnet,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1, activation='sigmoid') # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_resnet.compile(optimizer='adam',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model_resnet.build((None, img_height, img_width, 3))\n",
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "affad6de"
   },
   "source": [
    "Now, we will train the ResNet50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508665,
     "status": "ok",
     "timestamp": 1757778772648,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "2a59480c",
    "outputId": "385d530d-25dd-4814-ce18-92ae020975a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163/163 [==============================] - 274s 2s/step - loss: 0.4462 - accuracy: 0.7952 - val_loss: 0.4238 - val_accuracy: 0.8107\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 273s 2s/step - loss: 0.4079 - accuracy: 0.8200 - val_loss: 0.4073 - val_accuracy: 0.8242\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 273s 2s/step - loss: 0.3909 - accuracy: 0.8269 - val_loss: 0.2463 - val_accuracy: 0.9117\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 278s 2s/step - loss: 0.3922 - accuracy: 0.8167 - val_loss: 0.2027 - val_accuracy: 0.9308\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 272s 2s/step - loss: 0.3468 - accuracy: 0.8487 - val_loss: 0.2797 - val_accuracy: 0.8849\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 270s 2s/step - loss: 0.3395 - accuracy: 0.8494 - val_loss: 0.2358 - val_accuracy: 0.9047\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 274s 2s/step - loss: 0.3314 - accuracy: 0.8550 - val_loss: 0.2505 - val_accuracy: 0.8983\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 269s 2s/step - loss: 0.3357 - accuracy: 0.8519 - val_loss: 0.2279 - val_accuracy: 0.9145\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 274s 2s/step - loss: 0.3236 - accuracy: 0.8663 - val_loss: 0.1815 - val_accuracy: 0.9308\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 270s 2s/step - loss: 0.2909 - accuracy: 0.8738 - val_loss: 0.2066 - val_accuracy: 0.9202\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 # You can adjust the number of epochs\n",
    "history_resnet = model_resnet.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=test_ds # Use test_ds as validation data for monitoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fafae31"
   },
   "source": [
    "Now, we will build the third model using transfer learning with ConvNeXt-Tiny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 5691,
     "status": "ok",
     "timestamp": 1757779370602,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "cbfbad17",
    "outputId": "5f40e261-f13f-4e9d-afaa-ab462488892f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_2 (Sequential)   (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " convnext_tiny (Functional)  (None, 8, 8, 768)         27820128  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 768)               0         \n",
      " 1 (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27820897 (106.13 MB)\n",
      "Trainable params: 769 (3.00 KB)\n",
      "Non-trainable params: 27820128 (106.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Create the base model from the pre-trained ConvNeXtTiny model\n",
    "base_model_convnext = ConvNeXtTiny(input_shape=(img_height, img_width, 3),\n",
    "                                    include_top=False,\n",
    "                                    weights='imagenet')\n",
    "\n",
    "# Freeze the base model\n",
    "base_model_convnext.trainable = False\n",
    "\n",
    "# Build the model on top of the base model\n",
    "model_convnext = Sequential([\n",
    "    data_augmentation,\n",
    "    base_model_convnext,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1, activation='sigmoid') # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_convnext.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model_convnext.build((None, img_height, img_width, 3))\n",
    "model_convnext.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4681175"
   },
   "source": [
    "Now, we will train the ConvNeXt-Tiny model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1094692,
     "status": "ok",
     "timestamp": 1757780478752,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "6ad852de",
    "outputId": "4228f845-0cda-45df-bb9a-a155a9fd6fcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:43:40.877087: I external/local_xla/xla/service/service.cc:168] XLA service 0x36603aa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-14 01:43:40.877115: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757794421.051083       1 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-09-14 01:43:41.052319: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1481s 9s/step - loss: 0.6346 - accuracy: 0.6338 - val_loss: 0.4708 - val_accuracy: 0.8856\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 25002s 154s/step - loss: 0.5334 - accuracy: 0.7817 - val_loss: 0.3491 - val_accuracy: 0.9308\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 1712s 11s/step - loss: 0.4769 - accuracy: 0.8048 - val_loss: 0.3990 - val_accuracy: 0.8821\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 1715s 11s/step - loss: 0.4606 - accuracy: 0.8160 - val_loss: 0.3728 - val_accuracy: 0.8870\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 1546s 9s/step - loss: 0.4436 - accuracy: 0.8338 - val_loss: 0.3103 - val_accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 1546s 9s/step - loss: 0.4135 - accuracy: 0.8348 - val_loss: 0.3122 - val_accuracy: 0.9174\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 1524s 9s/step - loss: 0.4025 - accuracy: 0.8342 - val_loss: 0.3112 - val_accuracy: 0.9160\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 1503s 9s/step - loss: 0.4071 - accuracy: 0.8381 - val_loss: 0.2935 - val_accuracy: 0.9216\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.8419"
     ]
    }
   ],
   "source": [
    "epochs = 10 # You can adjust the number of epochs\n",
    "history_convnext = model_convnext.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=test_ds # Use test_ds as validation data for monitoring\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8c6d1dd"
   },
   "source": [
    "Now, we will create an ensemble of the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1757781492385,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "5e869e36",
    "outputId": "2a093316-b5f1-487f-b6f7-2155d614bce3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ efficientnetv2-b0   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resnet50            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convnext_tiny       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,820,128</span> │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ efficientnetv2-b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ convnext_tiny[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ efficientnetv2-b0   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │  \u001b[38;5;34m5,919,312\u001b[0m │ sequential_2[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1280\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resnet50            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │ \u001b[38;5;34m23,587,712\u001b[0m │ sequential_2[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convnext_tiny       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m768\u001b[0m) │ \u001b[38;5;34m27,820,128\u001b[0m │ sequential_2[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ efficientnetv2-b… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ convnext_tiny[\u001b[38;5;34m1\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │      \u001b[38;5;34m1,281\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │      \u001b[38;5;34m2,049\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m769\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average (\u001b[38;5;33mAverage\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense_5[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense_6[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,331,251</span> (218.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,331,251\u001b[0m (218.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,099</span> (16.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,099\u001b[0m (16.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,327,152</span> (218.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m57,327,152\u001b[0m (218.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "# Get the inputs of the individual models\n",
    "input_shape = (img_height, img_width, 3)\n",
    "input_tensor = Input(shape=input_shape)\n",
    "\n",
    "# Get the outputs of the individual models (before the final activation if possible, but sigmoid outputs are fine for averaging probabilities)\n",
    "# We need to apply the data augmentation to the input before feeding it to the base models\n",
    "augmented_input = data_augmentation(input_tensor)\n",
    "\n",
    "# Get the output from each trained model's base (unfrozen) part\n",
    "# We need to remove the data augmentation and the final dense layer from the individual models\n",
    "model_effnet_base_output = model_effnet.layers[1](augmented_input) # Get output after base_model_effnet\n",
    "model_resnet_base_output = model_resnet.layers[1](augmented_input) # Get output after base_model_resnet\n",
    "model_convnext_base_output = model_convnext.layers[1](augmented_input) # Get output after base_model_convnext\n",
    "\n",
    "\n",
    "# Apply GlobalAveragePooling2D and Dense layers from each model to their respective base outputs\n",
    "model_effnet_output = model_effnet.layers[2](model_effnet_base_output) # GlobalAveragePooling2D\n",
    "model_effnet_output = model_effnet.layers[3](model_effnet_output) # Dense\n",
    "\n",
    "model_resnet_output = model_resnet.layers[2](model_resnet_base_output) # GlobalAveragePooling2D\n",
    "model_resnet_output = model_resnet.layers[3](model_resnet_output) # Dense\n",
    "\n",
    "model_convnext_output = model_convnext.layers[2](model_convnext_base_output) # GlobalAveragePooling2D\n",
    "model_convnext_output = model_convnext.layers[3](model_convnext_output) # Dense\n",
    "\n",
    "\n",
    "# Average the predictions of the three models\n",
    "ensemble_output = Average()([model_effnet_output, model_resnet_output, model_convnext_output])\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble_model = Model(inputs=input_tensor, outputs=ensemble_output)\n",
    "\n",
    "# Compile the ensemble model (optimizer and loss function will be the same as individual models)\n",
    "ensemble_model.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# Display the ensemble model summary\n",
    "ensemble_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1876852d"
   },
   "source": [
    "Now, we will evaluate the performance of the ensemble model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52021,
     "status": "ok",
     "timestamp": 1757781554876,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "da89d3df",
    "outputId": "22a829c8-8a68-4e57-b13a-b67ccb15fe48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 656ms/step - accuracy: 0.9048 - loss: 0.2917\n",
      "Ensemble model loss on test data: 0.23552414774894714\n",
      "Ensemble model accuracy on test data: 0.9392655491828918\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble model on the test dataset\n",
    "loss, accuracy = ensemble_model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Ensemble model loss on test data: {loss}\")\n",
    "print(f\"Ensemble model accuracy on test data: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "437932d9"
   },
   "source": [
    "Now, we will make predictions using the ensemble model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164041,
     "status": "ok",
     "timestamp": 1757781735931,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "4d5cd507",
    "outputId": "73af56d1-b2bc-4e32-d86f-8efcb6eb9002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 820ms/step\n",
      "Sample Predictions:\n",
      "  Prediction: 0, True Label: 0\n",
      "  Prediction: 0, True Label: 0\n",
      "  Prediction: 0, True Label: 0\n",
      "  Prediction: 1, True Label: 0\n",
      "  Prediction: 0, True Label: 0\n",
      "  Prediction: 0, True Label: 0\n",
      "  Prediction: 1, True Label: 0\n",
      "  Prediction: 0, True Label: 0\n",
      "  Prediction: 0, True Label: 0\n",
      "  Prediction: 0, True Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for the test dataset\n",
    "predictions = ensemble_model.predict(test_ds)\n",
    "\n",
    "# The predictions are probabilities, convert them to class labels (0 or 1)\n",
    "# A threshold of 0.5 is commonly used for binary classification\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Display some predictions and their corresponding true labels\n",
    "print(\"Sample Predictions:\")\n",
    "for i in range(min(10, len(predicted_classes))): # Displaying first 10 predictions\n",
    "    # Get the true label for the i-th sample in the test_ds\n",
    "    # This requires iterating through the dataset, which can be inefficient for large datasets.\n",
    "    # For a comprehensive evaluation, use metrics like confusion matrix.\n",
    "    # This is just to show a few sample predictions.\n",
    "    true_label = np.concatenate([y for x, y in test_ds], axis=0)[i]\n",
    "    print(f\"  Prediction: {predicted_classes[i][0]}, True Label: {true_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60aeca0d"
   },
   "source": [
    "Finally, we will interpret the results and summarize our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "executionInfo": {
     "elapsed": 11971,
     "status": "ok",
     "timestamp": 1757781748384,
     "user": {
      "displayName": "Suraj Jayakumar",
      "userId": "16596262866308992375"
     },
     "user_tz": -330
    },
    "id": "405635d6",
    "outputId": "c9845f48-54a9-41fb-d886-1ccdac093dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.53      0.76      0.62        93\n",
      "   Non-Fraud       0.98      0.95      0.97      1323\n",
      "\n",
      "    accuracy                           0.94      1416\n",
      "   macro avg       0.75      0.86      0.79      1416\n",
      "weighted avg       0.95      0.94      0.94      1416\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Findings:\n",
      "- The ensemble model achieved an accuracy of 0.9393 on the test data.\n",
      "- The classification report provides detailed metrics (precision, recall, F1-score) for each class.\n",
      "- The confusion matrix shows the number of true positive, true negative, false positive, and false negative predictions.\n",
      "- These results can be used to identify potential fraudulent claims for further review.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the true labels from the test dataset\n",
    "true_labels = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_labels, predicted_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Summarize findings\n",
    "print(\"\\nSummary of Findings:\")\n",
    "print(f\"- The ensemble model achieved an accuracy of {accuracy:.4f} on the test data.\")\n",
    "print(\"- The classification report provides detailed metrics (precision, recall, F1-score) for each class.\")\n",
    "print(\"- The confusion matrix shows the number of true positive, true negative, false positive, and false negative predictions.\")\n",
    "print(\"- These results can be used to identify potential fraudulent claims for further review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "import os\n",
    "\n",
    "# Define the file path for saving the model\n",
    "model_save_path = os.path.join(os.getcwd(), \"ensemble_model.keras\")  # Save in current working directory\n",
    "\n",
    "# Save the ensemble model\n",
    "save_model(ensemble_model, model_save_path)\n",
    "\n",
    "print(f\"Ensemble model saved successfully to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPC0z4MNEL5kHSCQugLqHtt",
   "mount_file_id": "1kPeroFrcIwbGFSLld8V34uQSgfLwryx6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
