# Vehicle Damage Assessment - CNN Fraud Detection System

A modern deep learning solution for detecting fraudulent vehicle damage claims using Convolutional Neural Networks (CNN) with TensorFlow 2.x.

## ğŸš€ Quick Start

### 1. Setup Environment
```bash
# Clone the repository
git clone https://github.com/yourusername/Vehicle_Damage_Assessment.git
cd Vehicle_Damage_Assessment

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Train the Model
```bash
# Run the training notebook
jupyter notebook notebooks/vehicle_damage_cnn.ipynb
```

### 3. Run the Web Application
```bash
# Start the Streamlit app
cd src
streamlit run streamlit_app.py
```

## ğŸ“ Project Structure

```
Vehicle_Damage_Assessment/
â”œâ”€â”€ ğŸ“ data/                    # Training and testing datasets
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ Fraud/             # Fraudulent damage images
â”‚   â”‚   â””â”€â”€ Non-Fraud/         # Legitimate damage images
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ Fraud/
â”‚       â””â”€â”€ Non-Fraud/
â”œâ”€â”€ ğŸ“ models/                  # Trained model files
â”‚   â”œâ”€â”€ vehicle_damage_model.keras      # Main model (Keras format)
â”‚   â””â”€â”€ vehicle_damage_cnn_model.h5     # Backup model (HDF5 format)
â”œâ”€â”€ ğŸ“ notebooks/               # Jupyter notebooks
â”‚   â””â”€â”€ vehicle_damage_cnn.ipynb        # Main training notebook
â”œâ”€â”€ ğŸ“ src/                     # Source code
â”‚   â”œâ”€â”€ streamlit_app.py       # Web application
â”‚   â””â”€â”€ dataset.py             # Data loading utilities
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ¯ Features

### Core Functionality
- **CNN-Based Classification**: Deep learning model for fraud detection
- **Evidence-Based Analysis**: Step-by-step reasoning for predictions
- **Real-time Processing**: Upload and analyze images instantly
- **High Accuracy**: 96%+ accuracy on test dataset

### Web Interface
- **Modern UI**: Clean, intuitive Streamlit interface
- **Image Upload**: Drag-and-drop or click to upload
- **Detailed Analysis**: Layer-by-layer CNN interpretation
- **Risk Assessment**: Color-coded fraud probability indicators

## ğŸ”¬ Technical Details

### Model Architecture
- **3 Convolutional Layers**: Progressive feature extraction
- **MaxPooling**: Spatial dimension reduction
- **Dropout Regularization**: Prevents overfitting
- **Dense Layers**: Final classification
- **Softmax Output**: Probability distribution

### Training Specs
- **Framework**: TensorFlow 2.x / Keras
- **Optimizer**: Adam (learning rate: 1e-4)
- **Loss Function**: Categorical Crossentropy
- **Metrics**: Accuracy, Precision, Recall, AUC
- **Iterations**: 7,500 training iterations

## ğŸ® Usage Examples

### Training the Model
```python
# In the notebook
train(num_iterations=7500)
print_validation_accuracy(show_confusion_matrix=True)
```

### Using the Web App
1. Open `http://localhost:8501` in your browser
2. Upload a vehicle damage image
3. View fraud probability and evidence analysis
4. Interpret the CNN layer-by-layer reasoning

## ğŸ“Š Performance Metrics

- **Overall Accuracy**: 96.0%
- **Fraud Detection Precision**: 95.9%
- **Fraud Detection Recall**: 96.0%
- **AUC Score**: 95.7%

## ğŸ› ï¸ Development

### Environment Setup
```bash
# Development dependencies
pip install jupyter matplotlib seaborn
```

### File Organization
- Keep models in `/models` directory
- Source code in `/src` directory  
- Notebooks in `/notebooks` directory
- Training data in `/data` directory

## ğŸ”§ Configuration

### Model Parameters
- Image size: 128x128 pixels
- Batch size: 32
- Validation split: 16%
- Input channels: 3 (RGB)

### Environment Variables
No special environment variables required.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Support

For questions or issues:
- Open an issue on GitHub
- Check the notebook documentation
- Review the training logs

---

**Built with â¤ï¸ using TensorFlow, Streamlit, and modern deep learning techniques.**

---

## ğŸ§  **How the Neural Network Works**

### **1. Input Processing**
- **Image Format**: 128Ã—128Ã—3 RGB vehicle damage images
- **Data Preprocessing**: Images normalized to [0,1] range using `/255` division
- **Class Labels**: Binary classification - `['Fraud', 'Non-Fraud']`
- **Batch Processing**: Images processed in batches of 32 for efficient training

### **2. CNN Architecture Deep Dive**

#### **Layer 1: Convolutional Layer 1**
```
Input: 128Ã—128Ã—3 (RGB Image)
Filter Size: 3Ã—3
Number of Filters: 32
Activation: ReLU
Pooling: 2Ã—2 Max Pooling
Output: 64Ã—64Ã—32
```
- **Purpose**: Detects basic features like edges, corners, and simple patterns
- **Feature Maps**: Creates 32 different feature maps, each highlighting different aspects
- **Receptive Field**: 3Ã—3 sliding window captures local patterns

#### **Layer 2: Convolutional Layer 2**
```
Input: 64Ã—64Ã—32
Filter Size: 3Ã—3
Number of Filters: 32
Activation: ReLU
Pooling: 2Ã—2 Max Pooling
Output: 32Ã—32Ã—32
```
- **Purpose**: Combines basic features to detect more complex patterns
- **Feature Learning**: Learns combinations of edges to form shapes and textures
- **Spatial Reduction**: Further reduces spatial dimensions while preserving important features

#### **Layer 3: Convolutional Layer 3**
```
Input: 32Ã—32Ã—32
Filter Size: 3Ã—3
Number of Filters: 64
Activation: ReLU
Pooling: 2Ã—2 Max Pooling
Output: 16Ã—16Ã—64
```
- **Purpose**: Captures high-level features specific to damage patterns
- **Deep Features**: Learns complex combinations that might indicate fraud vs legitimate damage
- **Increased Filters**: 64 filters capture more diverse and complex patterns

#### **Layer 4: Flatten Layer**
```
Input: 16Ã—16Ã—64 = 16,384 features
Output: 1Ã—16,384 (flattened vector)
```
- **Purpose**: Converts 3D feature maps to 1D vector for fully connected layers
- **Information Preservation**: Maintains all learned features in linear format

#### **Layer 5: Fully Connected Layer**
```
Input: 16,384 features
Neurons: 128
Activation: ReLU
Dropout: Applied during training to prevent overfitting
Output: 128 features
```
- **Purpose**: Learns complex non-linear combinations of all extracted features
- **Decision Making**: Combines all visual patterns to make classification decisions
- **Feature Integration**: Synthesizes low-level and high-level features

#### **Layer 6: Output Layer**
```
Input: 128 features
Neurons: 2 (Fraud, Non-Fraud)
Activation: Softmax
Output: [probability_fraud, probability_non_fraud]
```
- **Purpose**: Final classification decision with probability scores
- **Softmax**: Ensures probabilities sum to 1.0
- **Binary Classification**: Outputs confidence for each class

---

## ğŸ” **How Classification Works**

### **Feature Learning Process**
1. **Edge Detection**: Layer 1 filters detect basic edges and textures in damage images
2. **Pattern Recognition**: Layer 2 combines edges to recognize shapes and damage patterns
3. **Complex Feature Extraction**: Layer 3 identifies sophisticated damage characteristics
4. **Decision Integration**: Fully connected layers combine all features for final classification

### **Fraud vs Legitimate Classification**
The network learns to distinguish between:

**Fraudulent Damage Indicators**:
- Inconsistent damage patterns
- Artificial or staged damage appearances
- Unusual damage locations or severity
- Patterns that don't match typical accident scenarios

**Legitimate Damage Indicators**:
- Natural impact patterns
- Consistent damage spread
- Realistic deformation and paint scratches
- Damage consistent with reported accident scenarios

### **Prediction Process**
1. **Image Input**: New vehicle damage image (128Ã—128Ã—3)
2. **Feature Extraction**: CNN layers extract hierarchical features
3. **Classification**: Final layer outputs probabilities [P_fraud, P_legitimate]
4. **Decision**: Higher probability determines classification
5. **Confidence Score**: Probability value indicates model confidence

---

## ğŸ“Š **Training Process**

### **Dataset Configuration**
- **Training Set**: ~84% of data for learning patterns
- **Validation Set**: 16% for monitoring performance during training
- **Test Set**: Separate set for final evaluation
- **Batch Size**: 32 images processed simultaneously

### **Optimization Details**
- **Loss Function**: Cross-entropy loss for binary classification
- **Optimizer**: Adam optimizer with adaptive learning rates
- **Performance Metrics**: Accuracy, validation loss tracking
- **Early Stopping**: Prevents overfitting by monitoring validation performance

### **Training Monitoring**
```python
# Training output example:
Epoch 1 --- Training Accuracy: 75.2%, Validation Accuracy: 73.1%, Validation Loss: 0.523
Epoch 2 --- Training Accuracy: 82.4%, Validation Accuracy: 79.8%, Validation Loss: 0.445
...
```

---

## ğŸ›  **Technical Implementation**

### **Key Functions**

#### **1. Convolutional Layer Creation**
```python
def new_conv_layer(input, num_input_channels, filter_size, num_filters, use_pooling=True):
    # Creates convolutional layer with specified parameters
    # Applies ReLU activation and optional max pooling
```

#### **2. Fully Connected Layer**
```python
def new_fc_layer(input, num_inputs, num_outputs, use_relu=True):
    # Creates dense layer for final classification
    # Optional ReLU activation for hidden layers
```

#### **3. Prediction Function**
```python
def predict_class(images):
    # Predicts class probabilities for input images
    # Returns both predicted classes and confidence scores
```

### **Filter Visualization**
The notebook includes advanced filter visualization to understand:
- What patterns each filter detects
- How different layers respond to damage features
- Visual interpretation of learned features

### **Performance Analysis**
- **Confusion Matrix**: Shows classification accuracy breakdown
- **Error Analysis**: Examines misclassified cases
- **Validation Curves**: Tracks training vs validation performance

---

## ğŸ“ **Study Points for Understanding**

### **1. Convolutional Operations**
- **Convolution**: How filters slide across images to detect patterns
- **Feature Maps**: Each filter creates a feature map highlighting specific patterns
- **Hierarchical Learning**: Lower layers detect simple features, higher layers detect complex ones

### **2. Pooling Operations**
- **Max Pooling**: Reduces spatial dimensions while keeping important features
- **Translation Invariance**: Makes the network robust to small position changes
- **Parameter Reduction**: Reduces computational complexity

### **3. Activation Functions**
- **ReLU**: Introduces non-linearity, allows learning complex patterns
- **Softmax**: Converts final layer outputs to probabilities

### **4. Training Concepts**
- **Backpropagation**: How the network learns from mistakes
- **Gradient Descent**: Optimization algorithm that improves performance
- **Overfitting Prevention**: Validation monitoring and early stopping

### **5. Evaluation Metrics**
- **Accuracy**: Percentage of correctly classified images
- **Loss**: Measure of how far predictions are from actual labels
- **Confusion Matrix**: Detailed breakdown of classification performance

---

## ğŸ“‚ **File Structure**
```
Vehicle_Damage_Assessment/
â”œâ”€â”€ tf1_cnn.ipynb              # Main CNN implementation notebook
â”œâ”€â”€ tf2_cnn.ipynb              # Alternative TF2 implementation
â”œâ”€â”€ dataset.py                 # Data loading and preprocessing utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ Fraud/             # Training fraud images
â”‚   â”‚   â””â”€â”€ Non-Fraud/         # Training legitimate images
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ Fraud/             # Test fraud images
â”‚       â””â”€â”€ Non-Fraud/         # Test legitimate images
â””â”€â”€ models/                    # Saved model checkpoints
```

---

## ğŸš€ **Business Impact**

### **Insurance Industry Applications**
1. **Automated Screening**: First-line defense against fraudulent claims
2. **Cost Reduction**: Reduces manual review time and costs
3. **Risk Management**: Identifies high-risk claims for detailed investigation
4. **Process Efficiency**: Accelerates legitimate claim processing

### **Performance Benefits**
- **Speed**: Instant classification of damage images
- **Consistency**: Eliminates human bias in initial screening
- **Scalability**: Can process thousands of claims simultaneously
- **Learning**: Improves over time with more data

---

## ğŸ”¬ **Advanced Features**

### **Model Interpretability**
- Filter visualization shows what the network "sees"
- Feature map analysis reveals decision-making process
- Error analysis identifies improvement opportunities

### **Robust Architecture**
- Multiple convolutional layers for hierarchical feature learning
- Dropout regularization prevents overfitting
- Validation monitoring ensures generalization

### **Production Ready**
- Batch processing for efficiency
- Model checkpointing for deployment
- Comprehensive evaluation metrics

---

## ğŸ“š **Learning Outcomes**

After studying this implementation, you'll understand:
1. **CNN Architecture**: How convolutional layers build feature hierarchies
2. **Image Classification**: Binary classification for fraud detection
3. **Deep Learning Pipeline**: Data â†’ Preprocessing â†’ Training â†’ Evaluation
4. **Model Optimization**: Training strategies and performance monitoring
5. **Business Applications**: Real-world AI applications in insurance
6. **Model Interpretability**: Understanding what the network learns

This project demonstrates a complete end-to-end deep learning solution for a real business problem, combining technical depth with practical applications.